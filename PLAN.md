Цель

Помочь выбрать и эффективно использовать модели (LLM, embeddings, классические ML и специализированные модели) для вашей мультимодальной системы и агентов, с учётом вашего текущего стека (ChatGPT-подписка, Altberries API, Supabase, ежедневный ETL и т.д.). Дать практические рекомендации по архитектуре, приоритетам, бенчмаркам, стоимости и примерам интеграции.

Контекст (из вашей информации)
- Вы — начинающий разработчик, уже интегрировали Altberries API и реализовали 4 метода, код в GitHub.
- Есть основная SQL-база и Supabase, ежедневный ETL-процесс, данные обновляются ежедневно.
- Следующий шаг — мультимодальная система и агенты; нужно сократить ручную работу с помощью автоматизированного помощника.

Чеклист шагов (план действий)
- [x] Проанализировать текущий стэк и требования (ChatGPT, Altberries, Supabase, ETL, GitHub)
- [ ] Определить основные кейсы и требования для системы (чат/генерация кода, семантический поиск, классификация, обработка сигналов и т.д.)
- [ ] Категоризировать задачи по потребностям модели (LLM генерация/код, embeddings/поиск, классические ML, специализированные модели)
- [ ] Составить список кандидатов моделей (OpenAI GPT-5.x, GPT-4.x/Codex, Anthropic Claude Sonnet/Haiku, DeepSig и др.) и их доступность (локально/облако)
- [ ] Для каждой категории определить критерии сравнения: качество, latency, цена, интеграция, безопасность, сложность поддержки
- [ ] Подготовить малый набор репрезентативных тестов/кейсов (примерные промпты, данные для embeddings, ML dataset) для бенчмарка
- [ ] Написать bench-скрипт (автоматический), который позволит сравнивать модели по метрикам качества, затрат и latency
- [ ] Провести пробный бенчмарк на 3–5 моделях и собрать метрики
- [ ] Проанализировать результаты и выбрать комбинации моделей для разных слоёв архитектуры (прототипирование, прод, массовые запросы, специализированные задачи)
- [ ] Разработать интеграционную архитектуру: маршрутизация запросов, кэш, валидация ответов (JSON schema), fallback на более мощную модель
- [ ] Реализовать пример интеграции/агента в вашем репозитории (скрипт или сервис), включая unit/integration tests
- [ ] Настроить мониторинг и алерты качества (ошибки, latency, cost spikes)
- [ ] Оценить стоимость при предполагаемых объёмах (QPS, запросы/мес) и предложить оптимизации затрат
- [ ] Документировать best-practices и шаблоны prompt’ов/интерфейсов для команды
- [ ] Пошаговый план по релизу и rollback стратегии

Текущее состояние по задачам по улучшениям агентов (работа в src/agents)
- [x] Подготовить unit-тесты для _tag и rows_to_brief
- [x] Установить pytest и запустить тесты (локально) — тесты зелёные
- [ ] Исправить найденные баги (если есть) — пока багов, выявленных тестами, нет
- [ ] Закоммитить тесты и изменения, открыть PR
- [ ] Настроить CI для автозапуска тестов (GitHub Actions)

Следующие шаги (коротко)
1) Закоммитить изменения и открыть PR (могу сделать коммиты и PR, если хотите).
2) Добавить простые unit-тесты в CI (GitHub Actions) — я могу подготовить workflow.
3) Продолжить работу по bench-скрипту и LLM-обёртке, если нужно.

Если подтверждаете — я могу сейчас создать git-коммиты с изменениями и открыть PR, а затем добавить CI workflow. Если хотите сначала просмотреть коммиты — скажите "показать git diff/коммиты".
